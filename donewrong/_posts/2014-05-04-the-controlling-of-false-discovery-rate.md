---
layout: post
tags: [основи статистики, множинні порівняння]
title: "&nbsp&nbspКонтроль частки хибних відкриттів"
author: Алекс Рейнхарт (переклав Олег Девіняк)
date: "2014-05-04" 
category: donewrong
---

Як ми вже казали, існують різні прийоми для врахування множинних порівнянь. Для прикладу, корекція Бонферроні стверджує, що потрібної частки хибних відкриттів можна досягти, якщо шукати значення \\(p<0.05/n\\), де \\(n\\) - кількість проведених статистичних тестів. Наприклад, якщо ваше дослідження містить 20 порівнянь, то потрібно використовувати критерій \\(р<0.0025\\), щоб бути впевненим, що шанс хибно присвоїти статистичну значимість неіснуючому ефекту не перевищує 5%.

Такий метод має недоліки. Знижуючи граничне значення \\(p\\), необхідне для присвоєння результату статистичної значимості, ми сильно знижуємо статистичну потужність, і не зможемо виявити не тільки хибні ефекти, але й істинні. Існують більш продвинуті процедури, ніж корекція Бонферроні, які використовують деякі статистичні нюанси для того, щоб підвищити статистичну потужність, але й вони далекі від ідеальних.

Більше того, вони не позбавлять вас від помилки базової частоти. Ви все одно можете бути обмануті граничним значенням р-величини, і можете хибно заявляти, що "всього 5% імовірність помилки". Ні, ви просто усуваєте деякі з хибнопозитивних результатів. Науковці більше зацікавлені у частці хибних відкриттів: яка частка з моїх статистично значимих результатів є хибнопозитивними? Чи є якийсь спосіб контролювати цю частку? 

Багато років такого способу не було. Як описано в попередніх матеріалах про помилку базової частоти, ми можемо обчислити частку хибних відкриттів тоді, коли знаємо скільки серед наших гіпотез є дійсно правдивими. Але в реальності таке знати чи вгадати неможливо. Нам слід спиратись виключно на результати, отримані при аналізі даних.

Кращу відповідь дали *Benjamini* та *Hochberg* у 1995 році. Вони розробили просту методику яка вказує, які з р-величин вважати статистично значимими. Якщо опустити математичні деталі, ось опис самої методики:

1. Проведіть свої статистичні тести і отримайте р-величини. Запишіть всі р-величини по порядку за зростанням.
2. Виберіть частку хибних відкриттів, назвемо її \\(q\\). А кількість статистичних тестів назвемо \\(m\\).
3. Знайдемо найбільшу р-величину, таку, щоб \\(p<iq/m\\), де \\(i\\) - номер р-величини у тому відсортованому списку.
4. Приймаємо цю р-величину і всі менші за неї р-величини статистично значимими.

Кінець! Методика гарантує, що серед визначених таким чином статистично значимимх результатів хибнопозитивними буде не більше \\(q*100\\) відсотків <a href="#Benjamini">\[17\]</a>. 

Методика Бенджаміні-Гохберга - швидка, ефективна та широко використовувана. Забезпечує кращу статистичну потужність, ніж корекція Бонферроні, а також достатньо проста. Звичайно, методика ця не ідеальна. У окремих випадках вона показувала нісенітницю, але завжди можливо скоректувати її таким чином, щоб справитись із контролем частки хибних відкриттів. Ця методика - основа для множинних порівнянь, і рішення про її використання набагато краще ніж не робити нічого.   

___

<div class="nohover">
<a name="Benjamini", id="anchor">[17] Y. Benjamini, Y. Hochberg. Controlling the false discovery rate: a practical and powerful approach to multiple testing. Journal of the Royal Statistical Society Series B, 289–300, 1995.</a>
</div>

  
